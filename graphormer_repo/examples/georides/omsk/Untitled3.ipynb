{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795761f0-66d3-4597-aecf-d065f225b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '/home/jovyan/graphormer_v2/')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch_geometric.datasets\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from ogb.lsc.pcqm4m_pyg import PygPCQM4MDataset\n",
    "import pyximport\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pyximport.install(setup_args={'include_dirs': np.get_include()})\n",
    "import os.path as osp\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "\n",
    "from torch_geometric.utils import add_self_loops, negative_sampling\n",
    "from graphormer.data.wrapper import preprocess_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56d87e63-251f-400f-a0ec-62daa5f68c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphormer.data.pyg_datasets.pyg_dataset import GraphormerPYGDataset\n",
    "from graphormer.data.dataset import GraphormerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b5aefa8-d5c5-4210-8405-77d5ab6d53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_geo_Omsk(InMemoryDataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None, split = 'train'):\n",
    "        super(single_geo_Omsk, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_dir + '/predict_data.pt')\n",
    "        # self.data = torch.load(self.processed_dir + '/' + f'{split}.pt')\n",
    "#         self.raw_dir = '/home/jovyan/'\n",
    "        \n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return '/home/jovyan/tte_data/'\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['omsk_full_routes_final_weather_L_NaN_filtered_FIXED.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['predict_data.pt']\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root)\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        print(self.processed_paths[0])\n",
    "    \n",
    "    def my_load_dataset(self):\n",
    "        return [self.data, self.slices]\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        # Read data\n",
    "        start_time = time.time()\n",
    "        data = pd.read_csv(osp.join('/home/jovyan/tte_data/', 'omsk_full_routes_final_weather_L_NaN_filtered_FIXED.csv'))\n",
    "        data = data[data['rebuildCount']<=1].reset_index(drop = True).copy()\n",
    "        # shape = int(data.shape[0]รท)\n",
    "        shape = int(10)\n",
    "        data = data[0:shape].copy()\n",
    "        \n",
    "        data = data.drop(columns = ['Unnamed: 0'])\n",
    "        data['hour'] = data['start_timestamp'].apply(lambda x: int(x[-10:-8]))\n",
    "        # Graph \n",
    "        graph_columns_gran = ['edges', 'time', 'speed', 'length']\n",
    "        edges = ['edges']\n",
    "        target = ['time']\n",
    "        node_features_gran = ['speed', 'length']\n",
    "\n",
    "        edge_features_agg = [' start_point_part', 'finish_point_part', 'day_period', 'week_period', 'clouds', 'snow', 'temperature', 'wind_dir', 'wind_speed', 'pressure','hour']\n",
    "\n",
    "        \n",
    "        all_speed = []\n",
    "        all_length = []\n",
    "        for i in range(0,shape):\n",
    "            data_row = data[i:i+1].reset_index(drop = True).copy()\n",
    "            speed_list = [int(x) for x in (data_row['speed'].values[0].replace(\"'\",'').split(','))]\n",
    "            list_length = [int(x) for x in (data_row['length'].values[0].replace(\"'\",'').split(','))]\n",
    "            all_speed.append(speed_list)\n",
    "            all_length.append(list_length)\n",
    "            \n",
    "        all_speed = [item for sublist in all_speed for item in sublist]\n",
    "        all_length = [item for sublist in all_length for item in sublist]\n",
    "    \n",
    "        data_split_dict = dict()\n",
    "        data_split_dict['all'] = np.arange(0, int(data.shape[0]))\n",
    "        \n",
    "        data_list = []\n",
    "        for i in data_split_dict['all']:\n",
    "            data_row = data.iloc[[i],].reset_index(drop = True).copy()\n",
    "\n",
    "            edge_list = [int(x) for x in (data_row['edges'].values[0].replace(\"'\",'').split(','))]\n",
    "            speed_list = [int(x) for x in (data_row['speed'].values[0].replace(\"'\",'').split(','))]\n",
    "            list_length = [int(x) for x in (data_row['length'].values[0].replace(\"'\",'').split(','))]\n",
    "\n",
    "            source = edge_list.copy()\n",
    "            target = edge_list[1:].copy() + [edge_list[0]].copy()\n",
    "\n",
    "            data_row_gran = pd.DataFrame()\n",
    "            data_row_gran['source'] = source\n",
    "            data_row_gran['target'] = target\n",
    "            data_row_gran['speed'] = speed_list\n",
    "            data_row_gran['length'] = list_length\n",
    "\n",
    "\n",
    "            target_val = data_row['RTA'].values[0]\n",
    "\n",
    "\n",
    "            data_row_gran['speed'] = data_row_gran['speed']/np.mean(speed_list)\n",
    "            data_row_gran['length'] = data_row_gran['length']/np.mean(list_length)\n",
    "\n",
    "            for col in edge_features_agg:\n",
    "                data_row_gran[col] = data_row[col].values[0]\n",
    "\n",
    "            total_nodes_list = list(set(list(data_row_gran.source.values)))\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(total_nodes_list)\n",
    "\n",
    "            data_row_gran['source'] = le.transform(data_row_gran.source.values)\n",
    "            data_row_gran['target'] = le.transform(data_row_gran.target.values)\n",
    "\n",
    "            total_nodes_list = list(set(list(data_row_gran.source.values)))\n",
    "\n",
    "            edge_index = torch.tensor(torch.from_numpy(data_row_gran[['source','target']].values.T),dtype = torch.long)\n",
    "\n",
    "\n",
    "            # Define tensor of nodes features\n",
    "            x = torch.tensor(torch.from_numpy(data_row_gran[['speed','length'] + edge_features_agg].values),dtype = torch.long)\n",
    "\n",
    "\n",
    "            # Define tensor of edge features\n",
    "            edge_num_feach = 1\n",
    "            edge_attr = torch.from_numpy(np.ones(shape = ((edge_index.size()[1]), edge_num_feach)))\n",
    "            edge_attr = torch.tensor(edge_attr,dtype = torch.long)\n",
    "\n",
    "            # Define tensor of targets\n",
    "            y = torch.tensor(target_val,dtype = torch.long)\n",
    "\n",
    "\n",
    "            data_graph = Data(x=x, edge_index = edge_index, edge_attr = edge_attr, y=y)\n",
    "            data_list.append(data_graph)\n",
    "        torch.save(self.collate(data_list), osp.join(self.processed_dir, 'predict_data.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1774e9a-c905-471a-981e-6a32af66ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "root = osp.join('dataset', 'omsk')\n",
    "raw_dir = osp.join(root, 'processed', 'data_omsk_1')\n",
    "data = single_geo_Omsk(root = raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b998fb2a-0e5f-4686-8852-ec45d103e9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[53, 1], edge_index=[2, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f28c150-91af-4756-a708-2f3d3e85b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[53, 1], edge_index=[2, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb3ae48c-63d6-40b5-b7d9-c4e9c3297a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start find path dijkstra\n",
      "dijkstra end with time 0.022580623626708984\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.010469436645507812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[54, 54], attn_edge_type=[53, 53, 1], edge_attr=[53, 1], edge_index=[2, 53], edge_input=[53, 53, 52, 1], in_degree=[53], out_degree=[53], spatial_pos=[53, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_item(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ef179da-0a98-4439-bc06-75e0fd8a5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start find path dijkstra\n",
      "dijkstra end with time 0.038013458251953125\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.0209200382232666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[73, 73], attn_edge_type=[72, 72, 1], edge_attr=[72, 1], edge_index=[2, 72], edge_input=[72, 72, 71, 1], in_degree=[72], out_degree=[72], spatial_pos=[72, 72], x=[72, 13], y=[1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_item(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52e5af9b-118e-498c-b922-a576f57bce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = torch.load('dataset/omsk/processed/data_omsk_1/train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b17302b-80d4-406d-8423-7294b01bcc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([       0,       53,      125,  ..., 24401063, 24401090, 24401141])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll[1]['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809d259-bd75-418e-bb04-cb3f7a4a5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_geo_Omsk\n",
    "GraphormerPYGDataset\n",
    "GraphormerDataset\n",
    "batched_data = self.dm.dataset_predict\n",
    "batched_data = BatchedDataDataset(\n",
    "        batched_data,\n",
    "        max_node=self.max_nodes(),\n",
    "        multi_hop_max_dist=self.cfg.multi_hop_max_dist,\n",
    "        spatial_pos_max=self.cfg.spatial_pos_max,\n",
    "    )\n",
    "\n",
    "    data_sizes = np.array([self.max_nodes()] * len(batched_data))\n",
    "\n",
    "    target = TargetDataset(batched_data)\n",
    "    # print('target 1 size', target.size())\n",
    "\n",
    "    dataset = NestedDictionaryDataset(\n",
    "        {\n",
    "            \"nsamples\": NumSamplesDataset(),\n",
    "            \"net_input\": {\"batched_data\": batched_data},\n",
    "            \"target\": target,\n",
    "        },\n",
    "        sizes=data_sizes,\n",
    "    )\n",
    "\n",
    "    if split == \"train\" and self.cfg.train_epoch_shuffle:\n",
    "        dataset = EpochShuffleDataset(\n",
    "            dataset, size=len(dataset), seed=self.cfg.seed\n",
    "        )\n",
    "\n",
    "    logger.info(\"Loaded {0} with #samples: {1}\".format(split, len(dataset)))\n",
    "\n",
    "    self.datasets[split] = dataset\n",
    "    self.batched_data = batched_data\n",
    "    return self.datasets[split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ba4a5-4e8c-4a1e-9598-7b60e15c4284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15c8cca7-58d3-44a6-9b6d-2620629689a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start find path dijkstra\n",
      "dijkstra end with time 0.016960620880126953\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.010648012161254883\n",
      "start find path dijkstra\n",
      "dijkstra end with time 0.01824355125427246\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.010607242584228516\n"
     ]
    }
   ],
   "source": [
    "from graphormer.data.pyg_datasets.pyg_dataset import GraphormerPYGDataset\n",
    "name = 'omsk'\n",
    "root = osp.join('dataset', name)\n",
    "raw_dir = osp.join(root, 'processed', 'data_omsk_1')\n",
    "data = single_geo_Omsk(root = raw_dir)\n",
    "proc_data = preprocess_item(data[0])\n",
    "GPYG = GraphormerPYGDataset_predict(None,seed,None,preprocess_item(data[0]),'omsk')\n",
    "dataset = NestedDictionaryDataset(\n",
    "            {\n",
    "                \"nsamples\": NumSamplesDataset(),\n",
    "                \"net_input\": {\"batched_data\": GPYG},\n",
    "                \"target\": batched_data,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79b8637e-9acf-4348-a65a-417c9b176a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.data.nested_dictionary_dataset.NestedDictionaryDataset at 0x7f8201bbb610>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0364f-c417-4a17-aa9d-fbf136c0422d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31c8c4-d559-47ff-837c-6d1ee7075e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3a73971-ea74-4226-baa3-4afe05b4cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start find path dijkstra\n",
      "dijkstra end with time 0.016582489013671875\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.010667562484741211\n"
     ]
    }
   ],
   "source": [
    "proc_data = preprocess_item(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b68a334e-3dc1-4a74-b136-6c723dffdae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4916/3168150063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     name)\n\u001b[0m",
      "\u001b[0;32m~/graphormer_v2/graphormer/data/pyg_datasets/pyg_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, seed, train_idx, valid_idx, test_idx, train_set, valid_set, test_set, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "seed = 71\n",
    "name = 'omsk'\n",
    "GraphormerPYGDataset(\n",
    "                    None,\n",
    "                    seed,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312cbed-dab8-4bbd-b65a-cbd267110de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9f9c2-aff2-4e32-b033-838f69d8f38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f1d96-288b-4910-beac-8e648678fd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "edfd9d9c-d63f-4af5-aa46-b1791465c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "class GraphormerPYGDataset_predict(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        seed: int = 0,\n",
    "        predict_idx=None,\n",
    "        predict_set=None,\n",
    "        name = None\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        if self.dataset is not None:\n",
    "            self.num_data = len(self.dataset)\n",
    "        self.seed = seed\n",
    "\n",
    "        self.num_data = len(predict_set) \n",
    "        self.predict_idx = predict_idx\n",
    "        self.predict_data = self.create_subset(predict_set)\n",
    "        self.__indices__ = None\n",
    "\n",
    "    def index_select(self, idx):\n",
    "        dataset = copy.copy(self)\n",
    "        dataset.dataset = self.dataset.index_select(idx)\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            dataset.num_data = idx.size(0)\n",
    "        else:\n",
    "            dataset.num_data = idx.shape[0]\n",
    "        dataset.__indices__ = idx\n",
    "        dataset.predict_data = None\n",
    "        dataset.predict_idx = None\n",
    "        return dataset\n",
    "\n",
    "    def create_subset(self, subset):\n",
    "        dataset = copy.copy(self)\n",
    "        dataset.dataset = subset\n",
    "        dataset.num_data = len(subset)\n",
    "        dataset.__indices__ = None\n",
    "        dataset.predict_data = None\n",
    "        dataset.predict_idx = None\n",
    "        return dataset\n",
    "\n",
    "    @lru_cache(maxsize=16)\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            print('idx:', idx)\n",
    "            print('self.dataset:', self.dataset)\n",
    "            item = self.dataset[idx]\n",
    "            item.idx = idx\n",
    "            item.y = item.y.reshape(-1)\n",
    "            return preprocess_item(item)\n",
    "        else:\n",
    "            raise TypeError(\"index to a GraphormerPYGDataset can only be an integer.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b1d353e0-85dc-47b8-a60a-e10464dbdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "GPYG = GraphormerPYGDataset_predict(\n",
    "                    data,\n",
    "                    seed,\n",
    "                    None,\n",
    "                    data,\n",
    "                    'omsk'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "68293ed0-dda5-4824-a01b-ca51fb8db981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0\n",
      "self.dataset: single_geo_Omsk(10)\n",
      "start find path dijkstra\n",
      "dijkstra end with time 0.01664423942565918\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.010808944702148438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[54, 54], attn_edge_type=[53, 53, 1], edge_attr=[53, 1], edge_index=[2, 53], edge_input=[53, 53, 52, 1], idx=0, in_degree=[53], out_degree=[53], spatial_pos=[53, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPYG[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f063c898-49d9-4289-8516-077210826b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[53, 1], edge_index=[2, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "815d0fd2-cb9d-4ee9-a153-314398b3fb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GraphormerPYGDataset_predict"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphormerPYGDataset_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c6fabd0b-8bdc-4d4b-9789-e22c32333e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GraphormerPYGDataset_predict"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphormerPYGDataset_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bba98598-3bbf-44cf-b73c-35a212979288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphormerPYGDataset_predict(10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPYG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a82dcc3-3521-4a91-960b-532c9ca9b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data = GPYG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e22d78b3-67bb-40e4-8c65-4412a51deb0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BatchedDataDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4916/373212305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m batched_data = BatchedDataDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mbatched_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmax_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmulti_hop_max_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_hop_max_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mspatial_pos_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_pos_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BatchedDataDataset' is not defined"
     ]
    }
   ],
   "source": [
    "batched_data = BatchedDataDataset(\n",
    "        batched_data,\n",
    "        max_node=self.max_nodes(),\n",
    "        multi_hop_max_dist=self.cfg.multi_hop_max_dist,\n",
    "        spatial_pos_max=self.cfg.spatial_pos_max,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1eff5e30-56af-4bcf-a92f-626fc3fc85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data import (\n",
    "    NestedDictionaryDataset,\n",
    "    NumSamplesDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a02fde48-3d7c-4e84-b259-4fe9cf95ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphormer.data.pyg_datasets.pyg_dataset import GraphormerPYGDataset\n",
    "from graphormer.data.dataset import (\n",
    "    BatchedDataDataset,\n",
    "    TargetDataset,\n",
    "    GraphormerDataset)\n",
    "\n",
    "batched_data = BatchedDataDataset(\n",
    "            batched_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3eea7500-6f4c-49a7-b11e-54c783f2164d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<graphormer.data.dataset.BatchedDataDataset at 0x7f8201bce990>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0c266d69-c159-469b-839a-c6941c7c28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = NestedDictionaryDataset(\n",
    "            {\n",
    "                \"nsamples\": NumSamplesDataset(),\n",
    "                \"net_input\": {\"batched_data\": batched_data},\n",
    "                \"target\": batched_data,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38e1fde8-2030-4b44-858a-9a87cd3fdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed20cf2b-a4f2-47cb-a299-cb484e811c47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4916/3034428010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# infer\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sample = utils.move_to_cuda(sample)\n",
    "    y = model(**sample[\"net_input\"])[:, 0, :].reshape(-1)\n",
    "    y_pred.extend(y.detach().cpu())\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3a308cbf-72fa-4e26-8d57-da690a489b53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4916/98545280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGPYG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch_itr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_dataset_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "batch_iterator = task.get_batch_iterator(dataset=GPYG)\n",
    "itr = batch_iterator.next_epoch_itr(shuffle=False, set_dataset_epoch=False)\n",
    "progress = progress_bar.progress_bar(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "778c05d4-f777-4875-b0d3-0d0971678115",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4916/491228505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGPYG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4916/1871950092.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "GPYG[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c97508-d351-4042-ace4-40bdcf4b458d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
