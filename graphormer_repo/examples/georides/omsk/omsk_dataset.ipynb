{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d5e2c7-1a58-49b6-9331-b73185134c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '/home/jovyan/graphormer_v2/')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch_geometric.datasets\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from ogb.lsc.pcqm4m_pyg import PygPCQM4MDataset\n",
    "import pyximport\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pyximport.install(setup_args={'include_dirs': np.get_include()})\n",
    "import os.path as osp\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "\n",
    "from torch_geometric.utils import add_self_loops, negative_sampling\n",
    "from graphormer.data.wrapper import preprocess_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73cb721-58c3-4100-9759-8da43813b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/graphormer_v2/examples'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from os import path\n",
    "\n",
    "path.dirname(path.dirname(path.abspath(''))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104b3bd-7707-4c45-b0f8-5dcfa9883da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2515e-bf75-473b-9b84-82f75914770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbc259f-9501-4440-b69b-258e5703318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphormer.models.graphormer import GraphormerModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85c50c-4a7c-454e-941d-8d61c1edcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bee5d-5c57-4d43-b0ca-224c2ace4d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45749fdf-232f-44cd-a4d4-76a22f45e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.transformer import TransformerModel\n",
    "zh2en = TransformerModel.from_pretrained(\n",
    "  '/path/to/checkpoints',\n",
    "  checkpoint_file='checkpoint_best.pt',\n",
    "  data_name_or_path='data-bin/wmt17_zh_en_full',\n",
    "  bpe='subword_nmt',\n",
    "  bpe_codes='data-bin/wmt17_zh_en_full/zh.code'\n",
    ")\n",
    "zh2en.translate('你好 世界')\n",
    "# 'Hello World'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df3dde-dd1b-44e8-b528-0c84286e5a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cee8939-6fb1-40ee-9d37-574f7c6e470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = osp.join('dataset', 'omsk')\n",
    "update_dir = osp.join(root, 'processed', 'data_omsk_1_upd')\n",
    "split = 'train'\n",
    "a = torch.load(update_dir + '/' + f'{split}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4461727-3446-447b-9d47-0a894d1497ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geo_Omsk(InMemoryDataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None, split = 'train'):\n",
    "        super(geo_Omsk, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_dir + '/' + f'{split}.pt')\n",
    "        # self.data = torch.load(self.processed_dir + '/' + f'{split}.pt')\n",
    "#         self.raw_dir = '/home/jovyan/'\n",
    "        \n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return '/home/jovyan/tte_data/'\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['omsk_full_routes_final_weather_L_NaN_filtered_FIXED.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt', 'test.pt', 'val.pt']\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root)\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        print(self.processed_paths[0])\n",
    "    \n",
    "    def my_load_dataset(self):\n",
    "        return [self.data, self.slices]\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        # Read data\n",
    "        start_time = time.time()\n",
    "        data = pd.read_csv(osp.join('/home/jovyan/tte_data/', 'omsk_full_routes_final_weather_L_NaN_filtered_FIXED.csv'))\n",
    "        data = data[data['rebuildCount']<=1].reset_index(drop = True).copy()\n",
    "        shape = int(data.shape[0])\n",
    "        data = data[0:shape].copy()\n",
    "        \n",
    "        data = data.drop(columns = ['Unnamed: 0'])\n",
    "        data['hour'] = data['start_timestamp'].apply(lambda x: int(x[-10:-8]))\n",
    "        # Graph \n",
    "        graph_columns_gran = ['edges', 'time', 'speed', 'length']\n",
    "        edges = ['edges']\n",
    "        target = ['time']\n",
    "        node_features_gran = ['speed', 'length']\n",
    "\n",
    "        edge_features_agg = [' start_point_part', 'finish_point_part', 'day_period', 'week_period', 'clouds', 'snow', 'temperature', 'wind_dir', 'wind_speed', 'pressure','hour']\n",
    "\n",
    "        \n",
    "        all_speed = []\n",
    "        all_length = []\n",
    "        for i in range(0,shape):\n",
    "            data_row = data[i:i+1].reset_index(drop = True).copy()\n",
    "            speed_list = [int(x) for x in (data_row['speed'].values[0].replace(\"'\",'').split(','))]\n",
    "            list_length = [int(x) for x in (data_row['length'].values[0].replace(\"'\",'').split(','))]\n",
    "            all_speed.append(speed_list)\n",
    "            all_length.append(list_length)\n",
    "            \n",
    "        all_speed = [item for sublist in all_speed for item in sublist]\n",
    "        all_length = [item for sublist in all_length for item in sublist]\n",
    "    \n",
    "        train_size = 0.8\n",
    "        test_size = 0.1\n",
    "        val_size = 0.1\n",
    "\n",
    "        data_split_dict = dict()\n",
    "        data_split_dict['train'] = np.arange(0, int(data.shape[0]*train_size))\n",
    "        data_split_dict['test'] = np.arange(int(data.shape[0]*train_size), int(data.shape[0]*(train_size+test_size)))\n",
    "        data_split_dict['val'] = np.arange(int(data.shape[0]*(train_size + test_size)),int((data.shape[0]*(train_size+test_size + val_size))))\n",
    "        \n",
    "        for split in data_split_dict.keys():\n",
    "            data_list = []\n",
    "            for i in data_split_dict[split]:\n",
    "                data_row = data.iloc[[i],].reset_index(drop = True).copy()\n",
    "\n",
    "                edge_list = [int(x) for x in (data_row['edges'].values[0].replace(\"'\",'').split(','))]\n",
    "                speed_list = [int(x) for x in (data_row['speed'].values[0].replace(\"'\",'').split(','))]\n",
    "                list_length = [int(x) for x in (data_row['length'].values[0].replace(\"'\",'').split(','))]\n",
    "\n",
    "                source = edge_list.copy()\n",
    "                target = edge_list[1:].copy() + [edge_list[0]].copy()\n",
    "\n",
    "                data_row_gran = pd.DataFrame()\n",
    "                data_row_gran['source'] = source\n",
    "                data_row_gran['target'] = target\n",
    "                data_row_gran['speed'] = speed_list\n",
    "                data_row_gran['length'] = list_length\n",
    "\n",
    "                \n",
    "                target_val = data_row['RTA'].values[0]\n",
    "\n",
    "\n",
    "                data_row_gran['speed'] = data_row_gran['speed']/np.mean(speed_list)\n",
    "                data_row_gran['length'] = data_row_gran['length']/np.mean(list_length)\n",
    "\n",
    "                for col in edge_features_agg:\n",
    "                    data_row_gran[col] = data_row[col].values[0]\n",
    "\n",
    "                total_nodes_list = list(set(list(data_row_gran.source.values)))\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                le.fit(total_nodes_list)\n",
    "\n",
    "                data_row_gran['source'] = le.transform(data_row_gran.source.values)\n",
    "                data_row_gran['target'] = le.transform(data_row_gran.target.values)\n",
    "\n",
    "                total_nodes_list = list(set(list(data_row_gran.source.values)))\n",
    "\n",
    "                edge_index = torch.tensor(torch.from_numpy(data_row_gran[['source','target']].values.T),dtype = torch.long)\n",
    "\n",
    "\n",
    "                # Define tensor of nodes features\n",
    "                x = torch.tensor(torch.from_numpy(data_row_gran[['speed','length'] + edge_features_agg].values),dtype = torch.long)\n",
    "\n",
    "                # Define tensor of edge features\n",
    "\n",
    "                # Define tensor of edge features\n",
    "                edge_num_feach = 1\n",
    "                edge_attr = torch.from_numpy(np.ones(shape = ((edge_index.size()[1]), edge_num_feach)))\n",
    "                edge_attr = torch.tensor(edge_attr,dtype = torch.long)\n",
    "\n",
    "                # Define tensor of targets\n",
    "                y = torch.tensor(target_val,dtype = torch.long)\n",
    "\n",
    "\n",
    "                data_graph = Data(x=x, edge_index = edge_index, edge_attr = edge_attr, y=y)\n",
    "                data_graph = preprocess_item(data_graph)\n",
    "                data_list.append(data_graph)\n",
    "            torch.save(data_list, osp.join(self.processed_dir, f'{split}.pt'))\n",
    "    \n",
    "    # def get(self, idx):\n",
    "    #     data = torch.load(osp.join(self.processed_dir, f'{idx}.pt'))\n",
    "    #     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a7e64f-3b85-4721-b563-9fec1453c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# output=[]\n",
    "# data = range(0,200000000)\n",
    "\n",
    "# def f(x):\n",
    "#     return x**2\n",
    "\n",
    "# def handler():\n",
    "#     p = multiprocessing.Pool(64)\n",
    "#     r=p.map(f, data)\n",
    "#     return r\n",
    "\n",
    "# a = handler()\n",
    "# if __name__ == '__main__':\n",
    "#     output.append(handler())\n",
    "\n",
    "# print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7d90d-0e3d-4ead-9503-23781ba7f79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa707388-4bfb-4fb7-a672-7e4ee0d603c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32277/26907472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'omsk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeo_Omsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_32277/1967903405.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, split)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_Omsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{split}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-graphormeronegpu-0/lib/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     59\u001b[0m                  pre_filter: Optional[Callable] = None):\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-graphormeronegpu-0/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-graphormeronegpu-0/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32277/1967903405.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mdata_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mdata_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graphormer_v2/graphormer/data/wrapper.py\u001b[0m in \u001b[0;36mpreprocess_item\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degree\u001b[0m  \u001b[0;31m# for undirected graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root = \"dataset/\" + 'omsk'\n",
    "a = geo_Omsk(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf14b8a-a158-4e17-b4e7-253ba21cb7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[53, 1], edge_index=[2, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a43d0d4-15c0-45c4-bbeb-980b173a8e3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31758/2315438600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgeo_Omsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31758/2773006497.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, split)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_Omsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{split}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#         self.raw_dir = '/home/jovyan/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "geo_Omsk(root, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac598c0-1b27-4bcd-8c7e-a31d137ad702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[53, 1], edge_index=[2, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.my_load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2ea334-1dd2-466f-8fc1-c0d768046b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess start\n",
      "start floyd\n",
      "start floyd_warshall\n",
      "end floyd_warshall\n",
      "end floyd\n",
      "floyd end with time 0.0019443035125732422\n",
      "start gen_edge_input\n",
      "start gen_edge_input\n",
      "start numpy\n",
      "end numpy\n",
      "('numpy end with time', 0.0009686946868896484)\n",
      "start sycle\n",
      "end sycle\n",
      "('sycle end with time', 0.07059931755065918)\n",
      "end gen_edge_input\n",
      "end gen_edge_input\n",
      "gen_edge_input end with time 0.07194352149963379\n",
      "preprocess end with time 0.08118867874145508\n",
      "shortest_path_result [[ 0  6 45 ...  5 48 49]\n",
      " [47  0 39 ... 52 42 43]\n",
      " [ 8 14  0 ... 13  3  4]\n",
      " ...\n",
      " [48  1 40 ...  0 43 44]\n",
      " [ 5 11 50 ... 10  0  1]\n",
      " [ 4 10 49 ...  9 52  0]]\n",
      "path [[ 0 50 50 ... 36 50 51]\n",
      " [52  0 49 ... 52 49 51]\n",
      " [52 52  0 ... 52 48 51]\n",
      " ...\n",
      " [52  0 49 ...  0 49 51]\n",
      " [52 52 52 ... 52  0  0]\n",
      " [46 50 50 ... 46 50  0]]\n",
      "max_dist 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[54, 54], attn_edge_type=[53, 53, 1], edge_attr=[53, 1], edge_index=[2, 53], edge_input=[53, 53, 52, 1], in_degree=[53], out_degree=[53], spatial_pos=[53, 53], x=[53, 13], y=[1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_item(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cafef7d-5ffd-4248-a977-3c9b9cbc0170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_Omsk(53926)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a4dbba-2813-4f03-b973-91b1b41a1723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_Omsk(53926)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4169266-74ee-4ae3-b287-3f736564c3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93690b9c-64f7-4a03-8a67-cf3d2ad23ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a9a83-1f6d-40e3-954e-de4f99e57fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bea86-1fe9-45f4-bb80-a76fb9908f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f158d-1da1-4333-b89a-5a6caf006f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0c0aa-7d08-4532-918e-48a7373f80b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ea8b4-75fb-42f8-aa58-cebdbefcfebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e9efe-c75d-4cdc-97ab-2b3703d8fab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386511dd-db11-4ecc-a6f5-d64e90abafe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c66158-027a-483a-8938-2a4c26f53e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086f481-2236-43a5-bec0-0a11aacbe946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc6f9a-2db6-464f-8266-d7af75bc03b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7390a1-cb3a-4dae-b1c0-edfb29966086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1a355-ba4c-44aa-9227-60cadebc78f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd52bb-b1b4-43a7-886e-ffdffa8965e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# cwd = os.getcwd()\n",
    "sys.path.insert(1, '/home/jovyan/graphormer_v2/')\n",
    "\n",
    "from graphormer.data.dataset import (\n",
    "    GraphormerDataset,\n",
    "    EpochShuffleDataset\n",
    ")\n",
    "\n",
    "from graphormer.models.graphormer import GraphormerModel\n",
    "from graphormer.tasks.graph_prediction import GraphPredictionTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c50cab-ec26-4250-8295-5fd289c8f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphormerDataset(\n",
    "                dataset_spec = 'omsk',\n",
    "                dataset_source = 'pyg',\n",
    "            )\n",
    "\n",
    "batched_data = BatchedDataDataset(\n",
    "            dataset.dataset_train,\n",
    "            max_node=16,\n",
    "            multi_hop_max_dist=5,\n",
    "            spatial_pos_max=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f158ef3f-870b-47b1-b726-e696fc3a3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 16:11:26 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 431406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairseq.data.nested_dictionary_dataset.NestedDictionaryDataset at 0x7f3c1adaf690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class cfg():\n",
    "    user_data_dir = \"\"\n",
    "    dataset_name = \"omsk\"\n",
    "    dataset_source = \"pyg\"\n",
    "    seed = 2\n",
    "    max_nodes = 16,\n",
    "    multi_hop_max_dist=5,\n",
    "    spatial_pos_max=2,\n",
    "    train_epoch_shuffle = False\n",
    "    \n",
    "a = cfg()\n",
    "task = GraphPredictionTask(a)\n",
    "task.load_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f4fc7d-abe9-4683-9eab-9cdca5ddb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator = task.get_batch_iterator(\n",
    "        dataset=task.dataset('train'),\n",
    "        max_positions=None,\n",
    "        ignore_invalid_inputs=True,\n",
    "        required_batch_size_multiple=1,\n",
    "        seed=10,\n",
    "        num_workers=4,\n",
    "        epoch=0,\n",
    "        data_buffer_size=64,\n",
    "        disable_iterator_cache=True,\n",
    "    )\n",
    "\n",
    "itr = batch_iterator.next_epoch_itr(shuffle=False, set_dataset_epoch=False)\n",
    "\n",
    "from fairseq.logging import progress_bar\n",
    "progress = progress_bar.progress_bar(itr, log_format = \"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8fa5f9f-4346-4585-ab71-eaf86ec56584",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(progress):\n",
    "    print(i)\n",
    "    # y = model(**sample[\"net_input\"])[:, 0, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30be1e83-1e72-47c8-b5c9-b560c2711514",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphormerDataset(\n",
    "                dataset_spec = 'omsk',\n",
    "                dataset_source = 'pyg',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dee050f-3fd0-4dd7-bcce-ca671a549b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphormer.data.wrapper import preprocess_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a233f506-76d2-4782-b31b-415addc09b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess start\n",
      "start floyd\n",
      "start floyd_warshall\n",
      "end floyd_warshall\n",
      "end floyd\n",
      "floyd end with time 0.0018382072448730469\n",
      "start gen_edge_input\n",
      "start gen_edge_input\n",
      "start numpy\n",
      "end numpy\n",
      "('numpy end with time', 0.0014154911041259766)\n",
      "start sycle\n",
      "end sycle\n",
      "('sycle end with time', 0.04857349395751953)\n",
      "end gen_edge_input\n",
      "end gen_edge_input\n",
      "gen_edge_input end with time 0.05029606819152832\n",
      "preprocess end with time 0.059174299240112305\n",
      "shortest_path_result [[ 0  2  3 ...  5  7 15]\n",
      " [40  0  1 ...  3  5 13]\n",
      " [39 41  0 ...  2  4 12]\n",
      " ...\n",
      " [37 39 40 ...  0  2 10]\n",
      " [35 37 38 ... 40  0  8]\n",
      " [27 29 30 ... 32 34  0]]\n",
      "path [[ 0 35 35 ... 35 39 40]\n",
      " [41  0  0 ... 21 39 40]\n",
      " [41 41  0 ... 21 39 40]\n",
      " ...\n",
      " [41 41 41 ...  0 27 40]\n",
      " [41 41 41 ... 41  0 32]\n",
      " [38 38 38 ... 38 39  0]]\n",
      "max_dist 41\n",
      "preprocess start\n",
      "start floyd\n",
      "start floyd_warshall\n",
      "end floyd_warshall\n",
      "end floyd\n",
      "floyd end with time 0.0015265941619873047\n",
      "start gen_edge_input\n",
      "start gen_edge_input\n",
      "start numpy\n",
      "end numpy\n",
      "('numpy end with time', 0.0006906986236572266)\n",
      "start sycle\n",
      "end sycle\n",
      "('sycle end with time', 0.04375267028808594)\n",
      "end gen_edge_input\n",
      "end gen_edge_input\n",
      "gen_edge_input end with time 0.04474306106567383\n",
      "preprocess end with time 0.0472102165222168\n",
      "shortest_path_result [[ 0  2  3 ...  5  7 15]\n",
      " [40  0  1 ...  3  5 13]\n",
      " [39 41  0 ...  2  4 12]\n",
      " ...\n",
      " [37 39 40 ...  0  2 10]\n",
      " [35 37 38 ... 40  0  8]\n",
      " [27 29 30 ... 32 34  0]]\n",
      "path [[ 0 35 35 ... 35 39 40]\n",
      " [41  0  0 ... 21 39 40]\n",
      " [41 41  0 ... 21 39 40]\n",
      " ...\n",
      " [41 41 41 ...  0 27 40]\n",
      " [41 41 41 ... 41  0 32]\n",
      " [38 38 38 ... 38 39  0]]\n",
      "max_dist 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[43, 43], attn_edge_type=[42, 42, 1], edge_attr=[42, 1], edge_index=[2, 42], edge_input=[42, 42, 41, 1], idx=3, in_degree=[42], out_degree=[42], spatial_pos=[42, 42], x=[42, 13], y=[1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_item(dataset.dataset_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89336da-8a1d-4d54-8190-61fb6e46da6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess start\n",
      "start floyd\n",
      "start floyd_warshall\n",
      "end floyd_warshall\n",
      "end floyd\n",
      "floyd end with time 0.00013136863708496094\n",
      "start gen_edge_input\n",
      "start gen_edge_input\n",
      "start numpy\n",
      "end numpy\n",
      "('numpy end with time', 3.5762786865234375e-05)\n",
      "start sycle\n",
      "end sycle\n",
      "('sycle end with time', 0.0005044937133789062)\n",
      "end gen_edge_input\n",
      "end gen_edge_input\n",
      "gen_edge_input end with time 0.0010328292846679688\n",
      "preprocess end with time 0.0020513534545898438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(attn_bias=[10, 10], attn_edge_type=[9, 9, 1], edge_attr=[9, 1], edge_index=[2, 9], edge_input=[9, 9, 8, 1], idx=10, in_degree=[9], out_degree=[9], spatial_pos=[9, 9], x=[9, 13], y=[1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_train[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
