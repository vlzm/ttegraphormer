{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b373ee-f9db-4289-b470-046c2a3879cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fairseq import checkpoint_utils, utils, options, tasks\n",
    "from fairseq.logging import progress_bar\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
    "import ogb\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "from os import path\n",
    "# sys.path.append( path.dirname( path.dirname( path.abspath(__file__) ) ) )\n",
    "import logging\n",
    "from data_class import geo_Omsk, single_geo_Omsk, GraphormerPYGDataset_predict, single_geo_Abakan\n",
    "import os.path as osp\n",
    "from torch_geometric.data import Dataset\n",
    "from functools import lru_cache\n",
    "import torch_geometric.datasets\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from ogb.lsc.pcqm4m_pyg import PygPCQM4MDataset\n",
    "import pyximport\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "pyximport.install(setup_args={'include_dirs': np.get_include()})\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "from torch_geometric.utils import add_self_loops, negative_sampling\n",
    "import copy\n",
    "from fairseq.data import (\n",
    "    NestedDictionaryDataset,\n",
    "    NumSamplesDataset,\n",
    ")\n",
    "import json\n",
    "import pathlib\n",
    "link = pathlib.Path().resolve()\n",
    "link = str(link).split('TransTTE')[0]\n",
    "GLOBAL_ROOT = link + 'TransTTE'\n",
    "\n",
    "sys.path.insert(2, GLOBAL_ROOT + '/graphormer_repo/graphormer')\n",
    "from data.wrapper import preprocess_item\n",
    "\n",
    "from pretrain import load_pretrained_model\n",
    "from data.pyg_datasets.pyg_dataset import GraphormerPYGDataset\n",
    "from data.dataset import (\n",
    "    BatchedDataDataset,\n",
    "    TargetDataset,\n",
    "    GraphormerDataset)\n",
    "\n",
    "def eval(args, use_pretrained, checkpoint_path=None, logger=None, data_name = None, predict_dataset = None):\n",
    "    cfg = convert_namespace_to_omegaconf(args)\n",
    "    np.random.seed(cfg.common.seed)\n",
    "    utils.set_torch_seed(cfg.common.seed)\n",
    "    seed = 71\n",
    "    \n",
    "    GPYG = GraphormerPYGDataset_predict(predict_dataset, seed, None, predict_dataset, data_name)\n",
    "    batched_data = BatchedDataDataset(GPYG)\n",
    "    data_sizes = np.array([128] * len(batched_data))\n",
    "    dataset_total = NestedDictionaryDataset(\n",
    "            {\n",
    "                \"nsamples\": NumSamplesDataset(),\n",
    "                \"net_input\": {\"batched_data\": batched_data},\n",
    "                \"target\": batched_data,\n",
    "            },\n",
    "        sizes=data_sizes,\n",
    "        )\n",
    "    ###\n",
    "    \n",
    "    ### initialize task\n",
    "    task = tasks.setup_task(cfg.task)\n",
    "    model = task.build_model(cfg.model)\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset=dataset_total\n",
    "    )\n",
    "    itr = batch_iterator.next_epoch_itr(shuffle=False, set_dataset_epoch=False)\n",
    "    progress = progress_bar.progress_bar(itr)\n",
    "    ###\n",
    "    \n",
    "    ### load checkpoint\n",
    "    model_state = torch.load(checkpoint_path)[\"model\"]\n",
    "    model.load_state_dict(model_state, strict=True, model_cfg=cfg.model)\n",
    "    model.to(torch.cuda.current_device())\n",
    "    del model_state\n",
    "    ###\n",
    "    \n",
    "    ### prediction\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, sample in enumerate(progress):\n",
    "            sample = utils.move_to_cuda(sample)\n",
    "            y = model(**sample[\"net_input\"])[:, 0, :].reshape(-1)\n",
    "            y_pred.extend(y.detach().cpu())\n",
    "            torch.cuda.empty_cache()\n",
    "    ###\n",
    "    \n",
    "    # save predictions\n",
    "    y_pred = torch.Tensor(y_pred)    \n",
    "    return y_pred\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def predict_time(dataset_name, predict_dataset):\n",
    "    \n",
    "    parser_dict = dict()\n",
    "    parser_dict['num-atoms'] = str(6656)\n",
    "    parser_dict['dataset_name'] = dataset_name\n",
    "    train_parser = options.get_training_parser()\n",
    "    train_parser.add_argument(\n",
    "            \"--split\",\n",
    "            type=str,\n",
    "        )\n",
    "    train_parser.add_argument(\n",
    "            \"--metric\",\n",
    "            type=str,\n",
    "        )\n",
    "    train_parser.add_argument(\n",
    "            \"--dataset_name\",\n",
    "            type=str,\n",
    "        )\n",
    "    train_args = options.parse_args_and_arch(\n",
    "        train_parser,\n",
    "        [\n",
    "            '--user-dir' , GLOBAL_ROOT + '/graphormer_repo/graphormer',\n",
    "            '--num-workers' , '10', \n",
    "            '--ddp-backend' , 'legacy_ddp', \n",
    "            '--dataset_name' , parser_dict['dataset_name'], \n",
    "            '--dataset-source' , 'pyg', \n",
    "            '--num-atoms' , parser_dict['num-atoms'], \n",
    "            '--task' , 'graph_prediction', \n",
    "            '--criterion' , 'l1_loss', \n",
    "            '--arch' , 'graphormer_slim',\n",
    "            '--num-classes' , '1', \n",
    "            '--batch-size' , '1', \n",
    "            '--save-dir' ,  GLOBAL_ROOT + '/graphormer_repo/examples/georides/omsk/ckpts/',\n",
    "            '--split' , 'valid', \n",
    "            '--metric' , 'rmse',\n",
    "            '--mode', 'predict'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    args = train_args\n",
    "    checkpoint_fname = 'checkpoint_last.pt'\n",
    "    checkpoint_path = Path(args.save_dir) / checkpoint_fname\n",
    "    y_preds = eval(args, False, checkpoint_path, None, args.dataset_name, predict_dataset)\n",
    "    return y_preds\n",
    "\n",
    "def graphormer_predict(pt_start, pt_end, dataset_name):\n",
    "    convert_table_valid = pd.read_csv(GLOBAL_ROOT + '/datasets/' + dataset_name + '/raw/convert_roads_valid.csv').dropna()\n",
    "    convert_table_valid['edge_coord_start'] = convert_table_valid['edge_coord_start'].apply(lambda x: json.loads(x))\n",
    "    convert_table_valid['edge_coord_end'] = convert_table_valid['edge_coord_end'].apply(lambda x: json.loads(x))\n",
    "\n",
    "    point_start = pt_start\n",
    "    point_end = pt_end\n",
    "\n",
    "    convert_table_valid['point_start_N'] = point_start[0]\n",
    "    convert_table_valid['point_start_E'] = point_start[1]\n",
    "    convert_table_valid['point_end_N'] = point_end[0]\n",
    "    convert_table_valid['point_end_E'] = point_end[1]\n",
    "\n",
    "    convert_table_valid['dist_start'] = convert_table_valid.apply(lambda x: (x['edge_coord_start'][0][0] - x['point_start_N'])**2 + (x['edge_coord_start'][0][1] - x['point_start_E'])**2, axis = 1)\n",
    "    convert_table_valid['dist_end'] = convert_table_valid.apply(lambda x: (x['edge_coord_end'][0][0] - x['point_end_N'])**2 + (x['edge_coord_end'][0][1] - x['point_end_E'])**2, axis = 1)\n",
    "    convert_table_valid['dist_mean'] = (convert_table_valid['dist_start'] + convert_table_valid['dist_end'])/2\n",
    "\n",
    "    predict_table = convert_table_valid.sort_values(by = ['dist_mean']).reset_index(drop = True)[:1]\n",
    "\n",
    "    dataset = single_geo_Abakan(predict_table)\n",
    "    dataset = dataset.process()\n",
    "\n",
    "    predicted_time = predict_time(dataset_name, dataset)\n",
    "\n",
    "    return [predict_table['edges_geo'], predicted_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c79a027-aa26-4d1c-919b-2b2254bcbb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 14:30:32 | WARNING | root | The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.\n",
      "2022-04-05 14:30:33 | INFO | rdkit | Enabling RDKit 2021.09.3 jupyter extensions\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start single\n",
      "0\n",
      "end single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/TransTTE/graphormer_inference/data_class.py:500: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(torch.from_numpy(data_row_gran[['source','target']].values.T),dtype = torch.long)\n",
      "/home/jovyan/TransTTE/graphormer_inference/data_class.py:504: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.from_numpy(data_row_gran[['speed','length'] + edge_features_agg].values),dtype = torch.long)\n",
      "/home/jovyan/TransTTE/graphormer_inference/data_class.py:510: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_attr = torch.tensor(edge_attr,dtype = torch.long)\n",
      "2022-04-05 14:30:46 | INFO | graphormer.models.graphormer | Namespace(_name='graphormer_slim', act_dropout=0.0, activation_fn='gelu', all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_graphormer_init=True, arch='graphormer_slim', attention_dropout=0.1, azureml_logging=False, batch_size=1, batch_size_valid=1, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='l1_loss', curriculum=0, data_buffer_size=10, dataset_impl=None, dataset_name='abakan', dataset_source='pyg', ddp_backend='legacy_ddp', ddp_comm_hook='none', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, edge_type='multi_hop', ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=80, encoder_ffn_embed_dim=80, encoder_layers=12, encoder_normalize_before=True, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, load_pretrained_model_output_layer=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_nodes=128, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, metric='rmse', min_loss_scale=0.0001, mode='predict', model_parallel_size=1, multi_hop_max_dist=5, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_atoms=6656, num_classes=1, num_edge_dis=128, num_edges=1536, num_in_degree=512, num_out_degree=512, num_shards=1, num_spatial=512, num_workers=10, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pretrained_model_name='none', profile=False, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/jovyan/TransTTE/graphormer_repo/examples/georides/omsk/ckpts/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_encoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, spatial_pos_max=1024, split='valid', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='graph_prediction', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_epoch_shuffle=False, train_subset='train', unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_plasma_view=False, use_sharded_state=False, user_data_dir='', user_dir='/home/jovyan/TransTTE/graphormer_repo/graphormer', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 0\n",
      "start find path dijkstra\n",
      "dijkstra end with time 0.028205156326293945\n",
      "start gen_edge_input dijkstra\n",
      "gen_edge_input dijkstra end with time 0.03565669059753418\n"
     ]
    }
   ],
   "source": [
    "from evaluate_points import graphormer_predict\n",
    "point_start = [91.4237220148, 53.72369937895]\n",
    "point_end = [91.43208882255, 53.726498733]\n",
    "a = graphormer_predict(point_start, point_end, 'abakan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfe7823-b7b2-47ab-8582-ff764b335926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0    [[91.423722   53.72369938]\\n [91.4276622  53.7...\n",
       " Name: edges_geo, dtype: object,\n",
       " tensor([594.3212])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf30073-f7dd-440a-a090-854db3133949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d4e35-5a84-4237-8a5f-b860e52569c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ab897-fac7-4f11-a5c3-61da8db2e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "План:\n",
    "    1. Разобраться как работает дейкстра, в каком виде он возвращает путь и что это за словарь\n",
    "    Путь это просто лист из точек. Этапред это время\n",
    "    2. Разобраться как действует джаваскрипт который принимает на вход словарь и рисует пути\n",
    "    3. Разобраться как перевести эджи в координаты\n",
    "    4. Сделать функцию, которая на вход принимает две точки и возвращает самый быстрый путь и время (для начала можно просто брать length and width, чтобы отработать скрипт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ce425-92dd-4f8a-9d19-cea12ec3a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
